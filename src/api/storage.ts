import { getApiBaseUrl } from '../utils/apiConfig'
import { useAuthStore } from '../store/authStore'

const STORAGE_BASE_URL = `${getApiBaseUrl()}/api/storage`

// è·å–è®¤è¯å¤´
const getAuthHeaders = (): HeadersInit => {
  const accessToken = useAuthStore.getState().accessToken
  return {
    'Content-Type': 'application/json',
    ...(accessToken ? { Authorization: `Bearer ${accessToken}` } : {}),
  }
}

// å¸¦è‡ªåŠ¨é‡è¯•çš„ fetch å°è£…
const fetchWithAuth = async (
  url: string,
  options: RequestInit = {}
): Promise<Response> => {
  const authStore = useAuthStore.getState()
  
  if (authStore.checkTokenExpiry() && authStore.refreshToken) {
    try {
      await authStore.refreshAccessToken()
    } catch (error) {
      console.error('Failed to refresh token:', error)
    }
  }

  const headers = getAuthHeaders()
  
  let response = await fetch(url, {
    ...options,
    headers: {
      ...headers,
      ...options.headers,
    },
  })

  if (response.status === 401 && authStore.refreshToken) {
    try {
      await authStore.refreshAccessToken()
      const newHeaders = getAuthHeaders()
      response = await fetch(url, {
        ...options,
        headers: {
          ...newHeaders,
          ...options.headers,
        },
      })
    } catch (error) {
      console.error('Token refresh failed, redirecting to login')
      authStore.clearAuth()
      window.location.href = '/login'
      throw error
    }
  }

  return response
}

// ============================================
// ç±»å‹å®šä¹‰
// ============================================

export type FileType = 
  | 'user_image' | 'user_video' | 'user_document'
  | 'friend_image' | 'friend_video' | 'friend_document'
  | 'group_image' | 'group_video' | 'group_document'

export type StorageLocation = 'user_files' | 'friend_messages' | 'group_files' | 'avatars'

export interface UploadRequestPayload {
  file_type: FileType
  storage_location: StorageLocation
  related_id?: string | null
  filename: string
  file_size: number
  content_type: string
  file_hash?: string
  force_upload?: boolean
  estimated_upload_time?: number
}

export interface UploadRequestResponse {
  mode: 'multipart'
  preview_support: 'inline_preview' | 'download_only'
  multipart_upload_id: string | null
  expires_in: number | null
  chunk_size: number | null
  total_chunks: number | null
  file_key: string
  max_file_size: number
  instant_upload: boolean
  existing_file_url: string | null
  // å¥½å‹æ–‡ä»¶ç§’ä¼ æ—¶è¿”å›
  message_uuid?: string
  message_send_time?: string
}

export interface UploadDirectResponse {
  file_url: string
  file_key: string
  file_size: number
  content_type: string
  preview_support: string
  // å¥½å‹æ–‡ä»¶ä¸Šä¼ æ—¶è¿”å›
  message_uuid?: string
  message_send_time?: string
}

export interface ConfirmUploadResponse {
  file_url: string
  file_key: string
  file_size: number
  content_type: string
  preview_support: string
  // å¥½å‹æ–‡ä»¶ä¸Šä¼ æ—¶è¿”å›
  message_uuid?: string
  message_send_time?: string
}

export interface PartUrlResponse {
  part_url: string
  part_number: number
  expires_in: number
}

export interface PresignedUrlResponse {
  presigned_url: string
  expires_at: string
  file_uuid: string
  file_size: number
  content_type: string
  warning: string | null
}

export interface FileItem {
  file_uuid: string
  filename: string
  file_size: number
  content_type: string
  preview_support: string
  created_at: string
  file_url: string
}

export interface FileListResponse {
  files: FileItem[]
  total: number
  page: number
  page_size: number
  total_pages: number
  has_more: boolean
}

// ============================================
// å·¥å…·å‡½æ•°
// ============================================

const SAMPLE_SIZE = 10 * 1024 * 1024 // 10MB

/**
 * è®¡ç®—æ–‡ä»¶çš„é‡‡æ · SHA-256 å“ˆå¸Œ
 * - å°æ–‡ä»¶ (< 30MB): å®Œæ•´å“ˆå¸Œ
 * - å¤§æ–‡ä»¶ (>= 30MB): é‡‡æ ·å“ˆå¸Œï¼ˆå…ƒä¿¡æ¯ + å¼€å¤´/ä¸­é—´/ç»“å°¾å„10MBï¼‰
 * 
 * æ³¨æ„: åªåŒ…å«æ–‡ä»¶å¤§å°å’Œå†…å®¹,ä¸åŒ…å«æ–‡ä»¶åç­‰å…ƒä¿¡æ¯,ç¡®ä¿ç›¸åŒå†…å®¹äº§ç”Ÿç›¸åŒå“ˆå¸Œ
 */
export async function calculateFileHash(file: File): Promise<string> {
  // åªåŒ…å«æ–‡ä»¶å¤§å°ä¿¡æ¯,ä¸åŒ…å«æ–‡ä»¶åç­‰å…ƒä¿¡æ¯
  const sizeBuffer = new TextEncoder().encode(`|size:${file.size}|`)
  
  let dataToHash: Uint8Array
  
  if (file.size <= SAMPLE_SIZE * 3) {
    // å°æ–‡ä»¶ï¼šè®¡ç®—å®Œæ•´å“ˆå¸Œ
    const fileBuffer = new Uint8Array(await file.arrayBuffer())
    dataToHash = new Uint8Array(sizeBuffer.length + fileBuffer.length)
    dataToHash.set(sizeBuffer, 0)
    dataToHash.set(fileBuffer, sizeBuffer.length)
  } else {
    // å¤§æ–‡ä»¶ï¼šé‡‡æ ·å“ˆå¸Œç­–ç•¥
    const chunks: Uint8Array[] = []
    
    // è¯»å–å¼€å¤´10MB
    const startBlob = file.slice(0, SAMPLE_SIZE)
    chunks.push(new Uint8Array(await startBlob.arrayBuffer()))
    
    // è¯»å–ä¸­é—´10MB
    const middleStart = Math.floor((file.size - SAMPLE_SIZE) / 2)
    const middleBlob = file.slice(middleStart, middleStart + SAMPLE_SIZE)
    chunks.push(new Uint8Array(await middleBlob.arrayBuffer()))
    
    // è¯»å–ç»“å°¾10MB
    const endBlob = file.slice(file.size - SAMPLE_SIZE, file.size)
    chunks.push(new Uint8Array(await endBlob.arrayBuffer()))
    
    // åˆå¹¶æ‰€æœ‰æ•°æ®
    const totalLength = sizeBuffer.length + chunks.reduce((sum, chunk) => sum + chunk.length, 0)
    dataToHash = new Uint8Array(totalLength)
    let offset = 0
    
    dataToHash.set(sizeBuffer, offset)
    offset += sizeBuffer.length
    
    for (const chunk of chunks) {
      dataToHash.set(chunk, offset)
      offset += chunk.length
    }
  }
  
  // è®¡ç®— SHA-256 å“ˆå¸Œ
  const bufferToHash = dataToHash.buffer.slice(
    dataToHash.byteOffset, 
    dataToHash.byteOffset + dataToHash.byteLength
  ) as ArrayBuffer
  const hashBuffer = await crypto.subtle.digest('SHA-256', bufferToHash)
  const hashArray = Array.from(new Uint8Array(hashBuffer))
  return hashArray.map(b => b.toString(16).padStart(2, '0')).join('')
}

/**
 * æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
 */
export function formatFileSize(bytes: number): string {
  if (bytes < 1024) return bytes + ' B'
  if (bytes < 1024 * 1024) return (bytes / 1024).toFixed(2) + ' KB'
  if (bytes < 1024 * 1024 * 1024) return (bytes / 1024 / 1024).toFixed(2) + ' MB'
  return (bytes / 1024 / 1024 / 1024).toFixed(2) + ' GB'
}

// ============================================
// é¢„ç­¾å URL ç¼“å­˜
// ============================================

interface CachedPresignedUrl {
  url: string
  expiresAt: string
  cachedAt: string
}

const presignedUrlCache: Record<string, CachedPresignedUrl> = {}

// ============================================
// API æ–¹æ³•
// ============================================

export const storageApi = {
  /**
   * è¯·æ±‚æ–‡ä»¶ä¸Šä¼ 
   * POST /api/storage/upload/request
   */
  requestUpload: async (payload: UploadRequestPayload): Promise<UploadRequestResponse> => {
    console.log('ğŸ“¤ è¯·æ±‚ä¸Šä¼ :', payload.filename)
    const response = await fetchWithAuth(`${STORAGE_BASE_URL}/upload/request`, {
      method: 'POST',
      body: JSON.stringify(payload),
    })

    if (!response.ok) {
      const error = await response.json().catch(() => ({ error: 'è¯·æ±‚ä¸Šä¼ å¤±è´¥' }))
      throw new Error(error.error || 'è¯·æ±‚ä¸Šä¼ å¤±è´¥')
    }

    const data = await response.json()
    
    if (data.instant_upload) {
      console.log('âš¡ ç§’ä¼ æˆåŠŸ!')
    }
    
    return data
  },

  /**
   * è·å–åˆ†ç‰‡ä¸Šä¼  URL
   * GET /api/storage/multipart/part_url?file_key=xxx&upload_id=xxx&part_number=1
   */
  getPartUrl: async (
    fileKey: string,
    uploadId: string,
    partNumber: number
  ): Promise<PartUrlResponse> => {
    const params = new URLSearchParams({
      file_key: fileKey,
      upload_id: uploadId,
      part_number: partNumber.toString(),
    })

    const response = await fetchWithAuth(`${STORAGE_BASE_URL}/multipart/part_url?${params}`, {
      method: 'GET',
    })

    if (!response.ok) {
      const error = await response.json().catch(() => ({ error: 'è·å–åˆ†ç‰‡URLå¤±è´¥' }))
      throw new Error(error.error || 'è·å–åˆ†ç‰‡URLå¤±è´¥')
    }

    return await response.json()
  },

  /**
   * ä¸Šä¼ å•ä¸ªåˆ†ç‰‡
   */
  uploadChunk: async (url: string, chunk: Blob): Promise<void> => {
    return new Promise((resolve, reject) => {
      const xhr = new XMLHttpRequest()
      
      xhr.onload = () => {
        if (xhr.status >= 200 && xhr.status < 300) {
          resolve()
        } else {
          reject(new Error(`åˆ†ç‰‡ä¸Šä¼ å¤±è´¥: HTTP ${xhr.status}`))
        }
      }
      
      xhr.onerror = () => reject(new Error('ç½‘ç»œé”™è¯¯'))
      
      xhr.open('PUT', url)
      xhr.send(chunk)
    })
  },

  /**
   * åˆ†ç‰‡ä¸Šä¼ æ–‡ä»¶ï¼ˆå¸¦è¿›åº¦å›è°ƒï¼‰
   */
  uploadWithMultipart: async (
    file: File,
    uploadInfo: UploadRequestResponse,
    onProgress?: (progress: {
      percent: number
      loaded: number
      total: number
      currentChunk: number
      totalChunks: number
    }) => void
  ): Promise<void> => {
    const chunkSize = uploadInfo.chunk_size || (30 * 1024 * 1024) // é»˜è®¤30MB
    const totalChunks = uploadInfo.total_chunks || Math.ceil(file.size / chunkSize)
    
    let totalUploaded = 0
    
    for (let i = 0; i < totalChunks; i++) {
      // 1. è·å–åˆ†ç‰‡é¢„ç­¾åURL
      const { part_url } = await storageApi.getPartUrl(
        uploadInfo.file_key,
        uploadInfo.multipart_upload_id!,
        i + 1
      )
      
      // 2. åˆ‡å‰²åˆ†ç‰‡
      const start = i * chunkSize
      const end = Math.min(start + chunkSize, file.size)
      const chunk = file.slice(start, end)
      
      // 3. ä¸Šä¼ åˆ†ç‰‡
      await storageApi.uploadChunk(part_url, chunk)
      
      // 4. æ›´æ–°è¿›åº¦
      totalUploaded += chunk.size
      if (onProgress) {
        onProgress({
          percent: (totalUploaded / file.size) * 100,
          loaded: totalUploaded,
          total: file.size,
          currentChunk: i + 1,
          totalChunks,
        })
      }
    }
  },

  /**
   * ç¡®è®¤ä¸Šä¼ å®Œæˆï¼ˆé¢„ç­¾åä¸Šä¼ ä¸“ç”¨ï¼‰
   * POST /api/storage/upload/confirm
   */
  confirmUpload: async (fileKey: string): Promise<ConfirmUploadResponse> => {
    console.log('âœ… ç¡®è®¤ä¸Šä¼ å®Œæˆ:', fileKey)
    const response = await fetchWithAuth(`${STORAGE_BASE_URL}/upload/confirm`, {
      method: 'POST',
      body: JSON.stringify({ file_key: fileKey }),
    })

    if (!response.ok) {
      const error = await response.json().catch(() => ({ error: 'ç¡®è®¤ä¸Šä¼ å¤±è´¥' }))
      throw new Error(error.error || 'ç¡®è®¤ä¸Šä¼ å¤±è´¥')
    }

    const data = await response.json()
    console.log('âœ… ä¸Šä¼ ç¡®è®¤æˆåŠŸ')
    return data
  },

  /**
   * å®Œæ•´çš„æ–‡ä»¶ä¸Šä¼ æµç¨‹ï¼ˆåˆ†ç‰‡ä¸Šä¼  + confirmç¡®è®¤ï¼‰
   * åŒ…å«å“ˆå¸Œè®¡ç®—ã€ç§’ä¼ æ£€æµ‹ã€åˆ†ç‰‡ä¸Šä¼ ã€ç¡®è®¤
   */
  uploadFile: async (
    file: File,
    fileType: FileType,
    storageLocation: StorageLocation,
    relatedId?: string,
    onProgress?: (progress: {
      percent: number
      loaded: number
      total: number
      currentChunk: number
      totalChunks: number
    }) => void
  ): Promise<{ fileUrl: string; isInstant: boolean; messageUuid?: string }> => {
    console.log('ğŸ”„ å¼€å§‹ä¸Šä¼ æµç¨‹:', file.name)
    
    // 1. è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
    console.log('ğŸ”¢ è®¡ç®—æ–‡ä»¶å“ˆå¸Œ...')
    const fileHash = await calculateFileHash(file)
    
    // 2. è¯·æ±‚ä¸Šä¼ 
    const uploadInfo = await storageApi.requestUpload({
      file_type: fileType,
      storage_location: storageLocation,
      related_id: relatedId,
      filename: file.name,
      file_size: file.size,
      content_type: file.type,
      file_hash: fileHash,
      force_upload: false,
    })
    
    // 3. æ£€æŸ¥ç§’ä¼ 
    if (uploadInfo.instant_upload) {
      console.log('âš¡ ç§’ä¼ æˆåŠŸ!')
      return {
        fileUrl: uploadInfo.existing_file_url!,
        isInstant: true,
        messageUuid: uploadInfo.message_uuid,
      }
    }
    
    // 4. åˆ†ç‰‡ä¸Šä¼ 
    console.log(`ğŸ“¤ å¼€å§‹åˆ†ç‰‡ä¸Šä¼ : ${uploadInfo.total_chunks} ä¸ªåˆ†ç‰‡`)
    await storageApi.uploadWithMultipart(file, uploadInfo, onProgress)
    
    // 5. ç¡®è®¤ä¸Šä¼ å®Œæˆ
    console.log('âœ… ç¡®è®¤ä¸Šä¼ ...')
    const confirmResult = await storageApi.confirmUpload(uploadInfo.file_key)
    
    console.log('âœ… ä¸Šä¼ æˆåŠŸ!')
      return {
      fileUrl: confirmResult.file_url,
        isInstant: false,
      messageUuid: confirmResult.message_uuid,
    }
  },

  /**
   * è·å–æ–‡ä»¶é¢„ç­¾å URLï¼ˆæ™®é€šæ–‡ä»¶ï¼‰
   * POST /api/storage/file/{uuid}/presigned_url
   */
  getPresignedUrl: async (
    uuid: string,
    operation: 'download' | 'preview' = 'download'
  ): Promise<string> => {
    // æ£€æŸ¥ç¼“å­˜
    const cached = presignedUrlCache[uuid]
    if (cached && cached.expiresAt) {
      const expiresTime = new Date(cached.expiresAt)
      const now = new Date()
      const remainingMs = expiresTime.getTime() - now.getTime()
      
      // è¿˜æœ‰5åˆ†é’Ÿä»¥ä¸Šï¼Œä½¿ç”¨ç¼“å­˜
      if (remainingMs > 5 * 60 * 1000) {
        console.log('âœ… ä½¿ç”¨ç¼“å­˜çš„é¢„ç­¾åURL')
        return cached.url
      }
    }
    
    console.log('ğŸ”— è·å–é¢„ç­¾åURL:', uuid)
    const response = await fetchWithAuth(`${STORAGE_BASE_URL}/file/${uuid}/presigned_url`, {
      method: 'POST',
      body: JSON.stringify({ operation }),
    })

    if (!response.ok) {
      const error = await response.json().catch(() => ({ error: 'è·å–é¢„ç­¾åURLå¤±è´¥' }))
      throw new Error(error.error || 'è·å–é¢„ç­¾åURLå¤±è´¥')
    }

    const data: PresignedUrlResponse = await response.json()
    
    // ç¼“å­˜URL
    presignedUrlCache[uuid] = {
      url: data.presigned_url,
      expiresAt: data.expires_at,
      cachedAt: new Date().toISOString(),
    }
    
    if (data.warning) {
      console.warn('âš ï¸', data.warning)
    }
    
    return data.presigned_url
  },

  /**
   * è·å–æ‰©å±•é¢„ç­¾å URLï¼ˆè¶…å¤§æ–‡ä»¶ï¼‰
   * POST /api/storage/file/{uuid}/presigned_url/extended
   */
  getExtendedPresignedUrl: async (
    uuid: string,
    estimatedDownloadTimeSeconds: number
  ): Promise<string> => {
    console.log('ğŸ”— è·å–æ‰©å±•é¢„ç­¾åURL:', uuid)
    const response = await fetchWithAuth(`${STORAGE_BASE_URL}/file/${uuid}/presigned_url/extended`, {
      method: 'POST',
      body: JSON.stringify({
        operation: 'download',
        estimated_download_time: estimatedDownloadTimeSeconds,
      }),
    })

    if (!response.ok) {
      const error = await response.json().catch(() => ({ error: 'è·å–æ‰©å±•é¢„ç­¾åURLå¤±è´¥' }))
      throw new Error(error.error || 'è·å–æ‰©å±•é¢„ç­¾åURLå¤±è´¥')
    }

    const data: PresignedUrlResponse = await response.json()
    
    if (data.warning) {
      console.warn('âš ï¸', data.warning)
    }
    
    return data.presigned_url
  },

  /**
   * è·å–å¥½å‹æ–‡ä»¶é¢„ç­¾å URL
   * POST /api/storage/friends-file/{uuid}/presigned-url
   */
  getFriendFilePresignedUrl: async (
    uuid: string,
    operation: 'download' | 'preview' = 'preview'
  ): Promise<string> => {
    // æ£€æŸ¥ç¼“å­˜
    const cacheKey = `friend_${uuid}`
    const cached = presignedUrlCache[cacheKey]
    if (cached && cached.expiresAt) {
      const expiresTime = new Date(cached.expiresAt)
      const now = new Date()
      const remainingMs = expiresTime.getTime() - now.getTime()
      
      if (remainingMs > 5 * 60 * 1000) {
        console.log('âœ… ä½¿ç”¨ç¼“å­˜çš„å¥½å‹æ–‡ä»¶é¢„ç­¾åURL')
        return cached.url
      }
    }
    
    console.log('ğŸ”— è·å–å¥½å‹æ–‡ä»¶é¢„ç­¾åURL:', uuid)
    const response = await fetchWithAuth(`${STORAGE_BASE_URL}/friends-file/${uuid}/presigned-url`, {
      method: 'POST',
      body: JSON.stringify({ operation }),
    })

    if (!response.ok) {
      const error = await response.json().catch(() => ({ error: 'è·å–å¥½å‹æ–‡ä»¶é¢„ç­¾åURLå¤±è´¥' }))
      throw new Error(error.error || 'è·å–å¥½å‹æ–‡ä»¶é¢„ç­¾åURLå¤±è´¥')
    }

    const data: PresignedUrlResponse = await response.json()
    
    // ç¼“å­˜URL
    presignedUrlCache[cacheKey] = {
      url: data.presigned_url,
      expiresAt: data.expires_at,
      cachedAt: new Date().toISOString(),
    }
    
    return data.presigned_url
  },

  /**
   * è·å–ä¸ªäººæ–‡ä»¶åˆ—è¡¨
   * GET /api/storage/files
   */
  getFileList: async (
    page: number = 1,
    limit: number = 20,
    sortBy: 'created_at' | 'file_size' = 'created_at',
    sortOrder: 'asc' | 'desc' = 'desc'
  ): Promise<FileListResponse> => {
    console.log('ğŸ“‹ è·å–æ–‡ä»¶åˆ—è¡¨')
    
    const params = new URLSearchParams({
      page: page.toString(),
      limit: limit.toString(),
      sort_by: sortBy,
      sort_order: sortOrder,
    })

    const response = await fetchWithAuth(`${STORAGE_BASE_URL}/files?${params}`, {
      method: 'GET',
    })

    if (!response.ok) {
      const error = await response.json().catch(() => ({ error: 'è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥' }))
      throw new Error(error.error || 'è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥')
    }

    const data = await response.json()
    return data
  },

  /**
   * æ¸…é™¤é¢„ç­¾åURLç¼“å­˜
   */
  clearPresignedUrlCache: (uuid?: string) => {
    if (uuid) {
      delete presignedUrlCache[uuid]
      delete presignedUrlCache[`friend_${uuid}`]
    } else {
      Object.keys(presignedUrlCache).forEach(key => delete presignedUrlCache[key])
    }
  },
}

